{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CHAPTER 5 금융에서의 머신러닝\n",
    "* 전통적인 머신러닝 알고리즘\n",
    "* 데이터 전처리, 평가, 백테스팅\n",
    "## 5.1 왜 머신러닝을 활용해야 하는가?\n",
    "* 알파 창출의 어려움\n",
    "* 투자 의사결정 속도\n",
    "* 투자자들의 다양한 요구\n",
    "### 5.1.1 머신러닝을 활용한 금융 데이터 분석\n",
    "## 5.2 머신러닝 알고리즘 소개\n",
    "* 지도 학습\n",
    "    * supervised learning\n",
    "    * 샘플 데이터를 활용해 트렌드 기반의 예측\n",
    "* 비지도 학습\n",
    "    * unsupervised learning\n",
    "    * 많은 변수들 간의 관계를 파악하는 데 사용\n",
    "### 5.2.1 지도 학습법 - 서포트 벡터 머신\n",
    "* 서포트 벡터 머신(SVM)\n",
    "    * support vector machine\n",
    "    * 데이터의 특성이 많지 않더라도 좋은 성능을 발휘\n",
    "    * 샘플이 많을시 속도와 메모리에 주의해야함\n",
    "### 5.2.2 트리 기반 모델\n",
    "* 앙상블 방법론\n",
    "    * 여러 개의 결정 트리(Decision Tree)를 결합하여 하나의 결정 트리보다 더 좋은 성능을 내는 머신러닝 기법\n",
    "    * 여러 개의 약 분류기(Weak Classifier)를 결합하여 강 분류기(Strong Classifier)를 만드는 것\n",
    "* 부스팅\n",
    "    * boosting\n",
    "    * 가중치를 활용하여 약 분류기를 강 분류기로 만드는 방법\n",
    "    * 오답에 높은 가중치를 부여하여 오답에 더욱 집중하도록 함\n",
    "    * 편향, 과소적합 문제를 훌륭하게 처리할 수 있음\n",
    "    * ex> 그래디어트 부스팅, XGBoost, LightGBM\n",
    "    * ![boosting](images/boosting.PNG)\n",
    "* 배깅\n",
    "    * Bagging(Bootstrap Aggregation)\n",
    "    * 샘플을 여러 번 뽑아(Bootstrap) 각 모델을 학습시켜 결과물을 집계하는 방법\n",
    "    * 분산을 감소시킴\n",
    "    * 금융 데이터는 과대적합이 더 큰 문제이므로 부스팅보단 배깅을 선호\n",
    "    * ex> 랜덤 포레스트\n",
    "    * ![bagging](images/bagging.PNG)\n",
    "* 오버피팅과 언더피팅\n",
    "    * ![overfitting vs underfitting](images/OverfittingVsUnderfitting.PNG)\n",
    "* 분산과 편향\n",
    "    * 분산이란?\n",
    "        * 데이터셋 내 데이터가 얼마나 떨어져 있는가를 나타내는 척도\n",
    "    * 편향이란?\n",
    "        * 데이터가 target으로부터 얼마나 떨어졌냐를 나타내는 척도\n",
    "    * ![variance Vs bias](images/VarianceVsBais.PNG)\n",
    "* 금융에서의 부스팅과 배깅\n",
    "    * 금융에서는 과대적합 문제에 더 집중되어져 있으므로 배깅을 더 선호\n",
    "### 5.2.3 비도 학습법 -차원 축소와 클러스터링\n",
    "* 차원 축소\n",
    "    * dimensionality reduction\n",
    "    * 고차원의 데이터를 차원을 줄여 모델을 효율적으로 만들기 위함\n",
    "    * ![svd](images/svd.PNG)\n",
    "* 클러스터링\n",
    "    * clustering\n",
    "    * 비슷하거나 공통의 특성을 가진 자산이나 종목을 찾아서 포트폴리오를 더 안정적으로 만들려는 목적\n",
    "    * ![clustering](images/clustering.PNG)\n",
    "\n",
    "## 5.3 금융 시계열 데이터에 대한 교차 검증 방법\n",
    "* 시계열 데이터는 시간 축과 강한 상관관계를 가짐\n",
    "* 사전 관찰 편향\n",
    "    * look ahead bias\n",
    "    * 투자자가 특정 일자에 접할 수 없는 데이터를 사용\n",
    "    * ![khold](images/khold.PNG)\n",
    "### 5.3.1 walk-forward 교차 검증과 blocking walk forward 교차 검증\n",
    "* walk-forward 교차 검증\n",
    "    * Stacked k-Fold Cross validation 이라고도 불림\n",
    "    * ![walk-forward](images/walk-forward.PNG)\n",
    "* blocking walk-forward 교차 검증\n",
    "    * ![blocking walk-forward](images/blocking_warlk-forward.PNG)\n",
    "### 5.3.2 엠바고와 퍼징\n",
    "* 퍼징과 엠바고\n",
    "    * ![purging](images/purging.PNG)\n",
    "    * ![embargo](images/embargo.PNG)\n",
    "\n",
    "## 5.4 금융에서의 데이터 전처리\n",
    "* 노이즈를 제거하는 전처리와 많은 변수의 타임 프레임을 맞추는 전처리 작업이 중요\n",
    "### 5.4.1 노이즈를 줄이는 방법\n",
    "* 신호 처리나 이미지 처리에서 효과적인 노이즈 제거 방법이 금융 시계열에서는 큰 효과를 내지 못함\n",
    "* 이동 평균\n",
    "    * 노이즈를 제고하고 추세를 파악하기 용이함\n",
    "* 지수 이동 평균\n",
    "    * 최근 가격에 더 큰 가중치를 주어 계산함\n",
    "    * 과거의 주가를 계싼에서 일시에 제외하지 않고 서서히 사라지게 함\n",
    "* 웨이블릿 변환\n",
    "    * wavelet transform\n",
    "    * 신호가 가지고 있는 비정산적 성질을 나태내는데 유용\n",
    "* PCA를 이용한 노이즈 제거\n",
    "    * pricipal component analysis(PCA)\n",
    "    * 노이즈를 제거하는 동시에 더 좋은 특성을 추출\n",
    "* 딥러닝 기반의 노이즈 제거 - 오토인코더\n",
    "    * 딥러닝을 사용한 차원 축소 기법\n",
    "    * 오토인코더에 히든 레이어 추가시 적층 오토인코더(SAE, stacked autoencoder)라 부름\n",
    "\n",
    "## 5.5 머신러닝을 활용한 전략의 평가 지표\n",
    "### 5.5.1 트렌드에 대한 가중치\n",
    "* 0.01% vs 10%\n",
    "    * 상승률에 따른 가중치 부여\n",
    "    * 다중 분류 문제로 변환\n",
    "### 5.5.2 레이블 데이터 불균형 문제\n",
    "* 등락 횟수가 최대한 비슷하게 레이블링 해야함\n",
    "### 5.5.3 다양한 지표 함께 보기\n",
    "* 단순히 '좋은' 모델의 개발 보단 구체적인 평가 지표에 대한 가이드라인을 제시해야 함\n",
    "\n",
    "## 5.6 백테스팅\n",
    "* 백테스팅 성과가 미래의 수익률을 보장해주지 않는다\n",
    "* '백테스팅을 신뢰할 수 있는가' = 금융계의 NP-hard 문제\n",
    "### 5.6.1 최대한 많은 경제적 시나리오를 포함하는 백테스팅 기간 설정하기\n",
    "### 5.6.2 수수료와 슬리피지 고려하기\n",
    "### 5.6.3 편향 고려하기\n",
    "* 생존 편향\n",
    "    * survivorship bias\n",
    "    * 상장 폐지 종목들 제외시 과장된 수익률을 낼 수 있다.\n",
    "* 사전 관찰 편향\n",
    "    * look-ahead bias\n",
    "    * 3월의 GDP 지수는 4월에 발표, 4월 이후에나 3월의 GDP지표를 사용해야 한다.\n",
    "* 심리적 인내 편향\n",
    "    * psychological tolerance bias\n",
    "    * 백테스팅 결과가 좋더라도 장시간 하락을 경험해야 한다면 투자를 지속하기 어렵다.\n",
    "### 5.6.4 특정 주가가 아닌 전체 자산 종류나 투자 영역에 대한 모델 개발하기\n",
    "* 특정 종목보단 섹터/인덱스로의 접근은 과적합을 줄일 수 있다.\n",
    "* 섹터/인덱스 별 모델 구축은 모델을 분산함으로써 리스크를 줄일 수 있다.\n",
    "### 5.6.5 여러 가지 지표 활용하기\n",
    "* 전략의 장단점을 파악하는 지표는 다양함\n",
    "    * 수익률\n",
    "    * 변동성\n",
    "    * 샤프 비율\n",
    "    * 최대 낙폭\n",
    "    * 샤프 지수\n",
    "    * 소르티노 지수\n",
    "    * 트레이너 지수\n",
    "        * 시장 민감도를 나타내는 베타지수로 초과수익률을 나눈 것\n",
    "        * 포트폴리오가 잘 분산되어 있는지 평가할 때 적합\n",
    "    * 젠센의 알파\n",
    "        * 시장 대비 실제 수익률\n",
    "### 5.6.6 시계열 분석에 맞는 교차 검증 방법 활용하기\n",
    "* 교차 검증 기법을 사용해 다양한 검증을 진행해야 함\n",
    "    * 신뢰도를 높이는 차선의 선택\n",
    "\n",
    "## 5.7 머신러닝 알고리즘 구현을 위한 사이킷런\n",
    "### 5.7.1 사이킷런 소개\n",
    "* 치트 시트\n",
    "    * ![사이킷런](images/sklearn_cheat-sheet.png)\n",
    "### 5.7.2 주요 모듈\n",
    "### 5.7.3 예제로 살펴보는 사이킷런 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# pip install -U scikit-learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.11737372]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "x_values = iris_data['data']\n",
    "y_values = iris_data['target']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_values, y_values)\n",
    "\n",
    "sample_iris = [[1,2,3,4]]\n",
    "print(model.predict(sample_iris))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.8 마치며\n",
    "* 대표적으로 사용되는 지도 학습법, 비지도 학습법 학습\n",
    "* 교차 검증 방법, 데이터 전처리, 측정 지표, 백테스팅 방법 검토"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}